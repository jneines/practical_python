{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af9c9c20-6a18-49d4-8fff-9a91f07c5bdd",
   "metadata": {},
   "source": [
    "# File handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a69267-021f-48c7-9c4b-90c8b2247a5b",
   "metadata": {},
   "source": [
    "The data to use in analyzes, simulation or display obviously needs to originate from somewhere. It can be live data retrieved from sensor measurments, downloaded from somewhere in the internet or take from some database.\n",
    "But the most usual way to work with data will probably be to read and write it from files at some place in the filesystem.\n",
    "Python offers a variety of support for this both in its standard library and by means of specialized third party packages. When it comes to working with different file formats it's mostly not the question *if* you can work with the file in Python, but just *how* to do it.\n",
    "There will be almost always someone, who had that problem before and made it happen by writing a Python package and publishing it to be freely available to everyone. \n",
    "\n",
    "But we should start with the most basic functionality first and use simple standard library functionality to deal with files. In its standard library Python wraps functionality of the OS itself to allow working witj files. So these low level builtin functions work pretty much the same in all programming languages and are not specific to Python. However some simplifications are made in the Python implementation, to make the API look more pythonic.\n",
    "\n",
    "To have some data to play with, we should create a text file with some contents first. And there is already the first special thing to take care of. Operating Systems dustinguish between text files (humand readable) and binary files. This is mainly to allow text files to have some control sequences in it to support an inner structure of the file. Control sequences exist for adding a *New Line* or *Carriage Return* for example to make a text end somewhere on the line and continue on the line below. Or adding a *tabulator* is possible as well to indent the text in a line. These originate from corresponding actions on typewriters and are implemented by using special unprintable characters that can be placed in the text. Unprintable characters are those outside of the letter, digit and punctuation range in the ASCII character set. For example a byte with the value of 10 will effectively cause a linefeed to happen, whilst a byte with the value 13 will cause a carriage return.\n",
    "Luckily for us, we do not have to create those bytes somehow to insert them into our readable text ourselves to cause the desired effect, but can simply use escape sequences for that. A line feed for example can be inserted by adding the sequencce \\n to our text. Adding a \\r will cause a carriage return to happen when interpreting the text, whilst inserting a \\t will indent the text to the right at that position. There are quite some more control sequences around. However these are the most common ones.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d1a42d-686a-4005-bef4-f148590c4fc3",
   "metadata": {},
   "source": [
    ":::{note} Please be aware that a proper new line works different on Windows and Unix like Operating systems. Whilst adding a \\n is enough for all Unix systems to have the following text start at the beginning of the next line, on Windows systems two control sequences have to be added. Use the sequence \\r\\n here for the same effect.\n",
    "Also notice, that this is only necessary, if you plan to edit or read your text with other applications outside your Python environment. Many external editors support switching the new line sequence to be used somewhere in their configuration or try to guess it correctly when reading the text in a file. When staying within the Python environment staying at a simple \\n sequence is probably the right idea, as you can always re-read the file in the same way you wrote it.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283ec5d0-0047-46ec-a76f-9fa705a6bc4f",
   "metadata": {},
   "source": [
    "So let's finally create our text file to play with and add some words to it, line by line.\n",
    "\n",
    "We create a list of words, `open` the file with the name \"words.txt\" for writing in text mode using the parameter \"w\" and assign the resulting file handle to a variable called `f`.\n",
    "Next we loop over the elements of our list of words using a for loop, which assigns the next word in the list to a variable `word` each iteration. \n",
    "By using. the `write` method we can add the text provided as an argument to it to the open file `f`. To have a text with a new line at the end we create a format string adding the new line control sequence \\n to our variable.\n",
    "Finally we have to close our file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "16bc9d70-cc68-4049-9b4b-b2a1fc17ee86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T08:50:21.501231Z",
     "iopub.status.busy": "2022-02-26T08:50:21.501035Z",
     "iopub.status.idle": "2022-02-26T08:50:21.509856Z",
     "shell.execute_reply": "2022-02-26T08:50:21.509433Z",
     "shell.execute_reply.started": "2022-02-26T08:50:21.501214Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "words = [\"Hello\", \"World\", \"February\", \"Eleven\", \"Python\", \"Data\", \"Cloud\", \"Wisdom\", \"Fun\"]\n",
    "f = open(\"words.txt\", \"w\")\n",
    "for word in words:\n",
    "    f.write(f\"{word}\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9596af78-4cc6-44e6-a8f6-27dfe143b9c8",
   "metadata": {},
   "source": [
    "Quite some things happened in the background here. Although the code looks as though the file would have been filled word by word to create line after line, actually this probably has been done in a buffered manner to optimize performance. It's very important to `close` the file after filling it to guarantee the data is really available as contents of a file in the filesystem, and not just somewhere in the layers of the operating system abstracting real file access away. If you don't explicitely close the file yourself, chances are that the words will be written to disk only when the application ends. If you need to re-read the data at some point whilst the application writing it is still running, you cannot guarantee the desired content is available.\n",
    "\n",
    "There are ways to force the operating system (to some degree) to perform the writes by actively forcing a sync using the `flush` method for example, or disabling the underlying buffer by setting its size to zero bytes. \n",
    "But for this simple task, just taking care of properly closing the file is enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c9677e-52fd-4feb-956e-d3c3cdfcda05",
   "metadata": {},
   "source": [
    "Actually Python offers a way to help you with this using a concept called *Context Managers*. These *Context Managers* help to free allocated resources when leaving the scope of a context. These *Context Managers* are not available per se for everything, but can be implemented by ourselves to keep resource handling clean when creating own matching tasks. We will see this later when working with classes in object orientated designs.\n",
    "\n",
    "A *Context Manager* exists however when working with files. It's implemented using the `with` builtin and used like this. We'll simply re-create our file of words once more using a *Context Manager*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "3de07af7-a86d-44d7-8a3c-b7848b7eb4e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T08:50:22.229877Z",
     "iopub.status.busy": "2022-02-26T08:50:22.229680Z",
     "iopub.status.idle": "2022-02-26T08:50:22.233051Z",
     "shell.execute_reply": "2022-02-26T08:50:22.232604Z",
     "shell.execute_reply.started": "2022-02-26T08:50:22.229859Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"words.txt\", \"w\") as f:\n",
    "    for word in words:\n",
    "        f.write(f\"{word}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287ddf2b-0b1c-4c23-9029-99e666ea9d8d",
   "metadata": {},
   "source": [
    "That's it. No longer taking care of closing the file f. Python closes it for you as soon as the `with` block is done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aa6e82-67a3-4f99-94dd-fa055fa7e608",
   "metadata": {},
   "source": [
    "Reading the words back works pretty much the same way. The algorithm for this works this way:\n",
    "\n",
    "- Create a new empty list to store the words in in.\n",
    "- Open the file for reading this time within a *Contet Manager*.\n",
    "- Read the file line by line using the `readline` method.\n",
    "- Stop processing if no more lines can be read.\n",
    "- Remove the newline sequence at the end by stripping away white space at the end using `rstrip`.\n",
    "- Add the resulting word to the list of words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0931272b-7d06-4f62-936f-417409f48463",
   "metadata": {},
   "source": [
    "One concept of implementing the algorithm could be the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "3d0b120d-7bb2-42b9-ac2f-bd802d5c9616",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T08:50:22.994513Z",
     "iopub.status.busy": "2022-02-26T08:50:22.994311Z",
     "iopub.status.idle": "2022-02-26T08:50:22.998334Z",
     "shell.execute_reply": "2022-02-26T08:50:22.997927Z",
     "shell.execute_reply.started": "2022-02-26T08:50:22.994496Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "World\n",
      "February\n",
      "Eleven\n",
      "Python\n",
      "Data\n",
      "Cloud\n",
      "Wisdom\n",
      "Fun\n"
     ]
    }
   ],
   "source": [
    "words2 = []\n",
    "with open(\"words.txt\", \"r\") as f:\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line:\n",
    "            break\n",
    "\n",
    "        word = line.rstrip()\n",
    "        print(word)\n",
    "        words2.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8901d0fc-3f42-4a75-a028-05b135ee0655",
   "metadata": {},
   "source": [
    "Newer versions of Python allow to use a new operator, called the walrus operator `:=` to be used to simplify reading the file further.\n",
    "\n",
    "I think that's quite an elegant approach this way, as it combines the check for continuing the loop and the exit check together with the variable asssignment in a readable and understandable concept. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "bb126f82-f75f-4590-86a6-ea3268ad2c01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T08:50:23.355615Z",
     "iopub.status.busy": "2022-02-26T08:50:23.355418Z",
     "iopub.status.idle": "2022-02-26T08:50:23.359620Z",
     "shell.execute_reply": "2022-02-26T08:50:23.359058Z",
     "shell.execute_reply.started": "2022-02-26T08:50:23.355599Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "World\n",
      "February\n",
      "Eleven\n",
      "Python\n",
      "Data\n",
      "Cloud\n",
      "Wisdom\n",
      "Fun\n"
     ]
    }
   ],
   "source": [
    "words2 = []\n",
    "with open(\"words.txt\", \"r\") as f:\n",
    "    while (line:=f.readline()):\n",
    "        word = line.rstrip()\n",
    "        print(word)\n",
    "        words2.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0a6be0-a559-44bb-90bd-64d7f9f2e564",
   "metadata": {},
   "source": [
    "The read back list looks like this now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "1ba59f4e-baa0-4a84-b554-5888066cb3b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T08:50:23.750013Z",
     "iopub.status.busy": "2022-02-26T08:50:23.749837Z",
     "iopub.status.idle": "2022-02-26T08:50:23.752721Z",
     "shell.execute_reply": "2022-02-26T08:50:23.752364Z",
     "shell.execute_reply.started": "2022-02-26T08:50:23.749996Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'World',\n",
       " 'February',\n",
       " 'Eleven',\n",
       " 'Python',\n",
       " 'Data',\n",
       " 'Cloud',\n",
       " 'Wisdom',\n",
       " 'Fun']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe08847-5a2f-4236-a8a2-53bf96405997",
   "metadata": {},
   "source": [
    "And it stands a comparison check with the original list as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a8ad1fd4-eae6-40c8-a993-fdee5dbf663a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T08:50:24.120838Z",
     "iopub.status.busy": "2022-02-26T08:50:24.120668Z",
     "iopub.status.idle": "2022-02-26T08:50:24.123932Z",
     "shell.execute_reply": "2022-02-26T08:50:24.123531Z",
     "shell.execute_reply.started": "2022-02-26T08:50:24.120821Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words == words2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddae202e-310c-4e66-991c-f7e30ac5363c",
   "metadata": {},
   "source": [
    "So we've correctly serialized and de-serialized a dataset our first data set here. Let's move on with a more complex example then. What about saving measurement or simulation data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd4800f-117b-4222-905a-73240bc0e7e8",
   "metadata": {},
   "source": [
    "## The many ways to read and write files\n",
    "\n",
    "### Handling file contents in one go."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474a9868-7397-45b3-bc0a-3df174f632ae",
   "metadata": {},
   "source": [
    "The example we've seen above was just one way of handling files. It suited our needs, as words had to be written line by line. So a line by line based approach was obviously matching best.\n",
    "The few data we had to handle would have allowed to read the file in one go. We can use the `read` method for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "6fb49663-5b36-4af0-9c0a-25e5c0ee9fae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T08:50:24.851349Z",
     "iopub.status.busy": "2022-02-26T08:50:24.851085Z",
     "iopub.status.idle": "2022-02-26T08:50:24.854769Z",
     "shell.execute_reply": "2022-02-26T08:50:24.854244Z",
     "shell.execute_reply.started": "2022-02-26T08:50:24.851319Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "World\n",
      "February\n",
      "Eleven\n",
      "Python\n",
      "Data\n",
      "Cloud\n",
      "Wisdom\n",
      "Fun\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"words.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5eaddf4-37ed-4054-b89c-e38bdaabe9cf",
   "metadata": {},
   "source": [
    "The output of the result pretty much looks the same here, though when looking more closely it's not quite the case. This time we've printed the whole contents of the file at once including the *newline* control sequences `\\n`, which structure the text to a line by line output.\n",
    "The result is still a string, so to have the original input back, we need to process a little more.\n",
    "\n",
    "The string type offers a handy method for that called `split`. It takes a character as an argument which should be used as a separator to split the string into a list of strings, the words in our case. If we use the *newline* control sequence `\\n` for splitting, we should be able to re-create our input. Let's see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "5ab868c2-a706-4911-9806-eae7e68fb808",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T08:50:25.222456Z",
     "iopub.status.busy": "2022-02-26T08:50:25.222280Z",
     "iopub.status.idle": "2022-02-26T08:50:25.225851Z",
     "shell.execute_reply": "2022-02-26T08:50:25.225420Z",
     "shell.execute_reply.started": "2022-02-26T08:50:25.222438Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'World',\n",
       " 'February',\n",
       " 'Eleven',\n",
       " 'Python',\n",
       " 'Data',\n",
       " 'Cloud',\n",
       " 'Wisdom',\n",
       " 'Fun',\n",
       " '']"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words2 = text.split(\"\\n\")\n",
    "words2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "6a71551b-0bdb-4193-bcbd-8402b57109de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T08:50:25.414872Z",
     "iopub.status.busy": "2022-02-26T08:50:25.414699Z",
     "iopub.status.idle": "2022-02-26T08:50:25.417713Z",
     "shell.execute_reply": "2022-02-26T08:50:25.417292Z",
     "shell.execute_reply.started": "2022-02-26T08:50:25.414855Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words2 == words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882a3f3d-ca3c-4efb-8187-afe5dbce79cf",
   "metadata": {},
   "source": [
    "Okay, so we're not quite there. Theres a little trailing item here, which let's our result differ from the original input, and empty string. This is because we've written our words that way to the file, adding a *newline* character to the end of each word, also the last one.\n",
    "The `split` method will always create a result with items to the left *and* the right of the provided separator, so we receive on more item here because of the very last separating *newline* character here. \n",
    "But we already know the answer to that. We just need to leave the last item out after splitting the text to receive our input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f3fc065d-e783-4d09-9713-40ab22c41e69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T08:50:25.774733Z",
     "iopub.status.busy": "2022-02-26T08:50:25.774561Z",
     "iopub.status.idle": "2022-02-26T08:50:25.778247Z",
     "shell.execute_reply": "2022-02-26T08:50:25.777801Z",
     "shell.execute_reply.started": "2022-02-26T08:50:25.774716Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'World',\n",
       " 'February',\n",
       " 'Eleven',\n",
       " 'Python',\n",
       " 'Data',\n",
       " 'Cloud',\n",
       " 'Wisdom',\n",
       " 'Fun']"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words2 = text.split(\"\\n\")[:-1]\n",
    "words2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3617729f-a639-4e4c-9dbc-e0101bcb6ab2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T08:50:25.966172Z",
     "iopub.status.busy": "2022-02-26T08:50:25.966013Z",
     "iopub.status.idle": "2022-02-26T08:50:25.968899Z",
     "shell.execute_reply": "2022-02-26T08:50:25.968512Z",
     "shell.execute_reply.started": "2022-02-26T08:50:25.966157Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words2 == words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5c4eb5-97d1-479f-9f3c-7484c0c36229",
   "metadata": {},
   "source": [
    "There's also the inverse operation to splitting a text into items, which is `join`. By using this we can create a symmetrical file handling operation again, very much like the initial approach, where we've written our words line by line, to read them back line by line afterwards.\n",
    "This time we're about to join a list of words before writing it in one go, followed by reading it as a whole and splitting it into words again. It goes like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4431ac7e-e9da-4de8-8c93-1e8f53fee24e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T08:50:26.337003Z",
     "iopub.status.busy": "2022-02-26T08:50:26.336763Z",
     "iopub.status.idle": "2022-02-26T08:50:26.340314Z",
     "shell.execute_reply": "2022-02-26T08:50:26.339911Z",
     "shell.execute_reply.started": "2022-02-26T08:50:26.336986Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "World\n",
      "February\n",
      "Eleven\n",
      "Python\n",
      "Data\n",
      "Cloud\n",
      "Wisdom\n",
      "Fun\n"
     ]
    }
   ],
   "source": [
    "text = \"\\n\".join(words)\n",
    "print(text)\n",
    "\n",
    "with open(\"words.txt\", \"w\") as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bf2c22-fd7c-46df-83e2-3a45131a1515",
   "metadata": {},
   "source": [
    "This joins the words in our list using the *newline* character and writes it to the file. And reading it back works as expected now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "5b9ac6db-6a3a-4803-8683-086cc4f8e323",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T08:50:26.707212Z",
     "iopub.status.busy": "2022-02-26T08:50:26.707036Z",
     "iopub.status.idle": "2022-02-26T08:50:26.710709Z",
     "shell.execute_reply": "2022-02-26T08:50:26.710295Z",
     "shell.execute_reply.started": "2022-02-26T08:50:26.707194Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'World',\n",
       " 'February',\n",
       " 'Eleven',\n",
       " 'Python',\n",
       " 'Data',\n",
       " 'Cloud',\n",
       " 'Wisdom',\n",
       " 'Fun']"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"words.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "words2 = text.split(\"\\n\")\n",
    "words2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "0a05dea3-d229-4212-961b-6ace2a5a142a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T08:50:26.887326Z",
     "iopub.status.busy": "2022-02-26T08:50:26.887148Z",
     "iopub.status.idle": "2022-02-26T08:50:26.890344Z",
     "shell.execute_reply": "2022-02-26T08:50:26.889926Z",
     "shell.execute_reply.started": "2022-02-26T08:50:26.887310Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words2 == words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81452d70-c732-4835-9436-e2e220cf9a94",
   "metadata": {},
   "source": [
    "### Reading and Writiing the file character by character."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54deb009-ef29-4dae-b66a-9946804a9dbb",
   "metadata": {},
   "source": [
    "We could have read the file contents in smaller chunks defined by a size as well. This would be the approach to use if you know nothing about the inner structures of the file to be processed. Say you're reading a very large file of words, a real dictionary maybe, without and structuring elements, so no *newline* characters inside. Then the `readline` approach won't help here, as there are no such lines in the file. \n",
    "The file might also be to big to be handled in one go as it won't fit into RAM. In that case we have to read the text in small chunks.\n",
    "We can again use the `read` method for that, as it takes an optional argument to specify the size of the chunk to read when called.\n",
    "In our simple case here, we will re-create the text string to hold the file contents first and split the text afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "6e75f2b5-6d04-4bfc-9acf-d436ffa30fe3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T08:50:27.462751Z",
     "iopub.status.busy": "2022-02-26T08:50:27.462550Z",
     "iopub.status.idle": "2022-02-26T08:50:27.465985Z",
     "shell.execute_reply": "2022-02-26T08:50:27.465630Z",
     "shell.execute_reply.started": "2022-02-26T08:50:27.462722Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "World\n",
      "February\n",
      "Eleven\n",
      "Python\n",
      "Data\n",
      "Cloud\n",
      "Wisdom\n",
      "Fun\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\n",
    "with open(\"words.txt\", \"r\") as f:\n",
    "    while chunk:=f.read(4):\n",
    "        text+=chunk\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "423b184c-67c4-414c-9076-a08fe0662a22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T08:50:27.642466Z",
     "iopub.status.busy": "2022-02-26T08:50:27.642296Z",
     "iopub.status.idle": "2022-02-26T08:50:27.645683Z",
     "shell.execute_reply": "2022-02-26T08:50:27.645212Z",
     "shell.execute_reply.started": "2022-02-26T08:50:27.642449Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'World',\n",
       " 'February',\n",
       " 'Eleven',\n",
       " 'Python',\n",
       " 'Data',\n",
       " 'Cloud',\n",
       " 'Wisdom',\n",
       " 'Fun']"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words2 = text.split(\"\\n\")\n",
    "words2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "ac8ac943-c30c-4b03-ab0e-95255161d93a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T08:50:27.833799Z",
     "iopub.status.busy": "2022-02-26T08:50:27.833623Z",
     "iopub.status.idle": "2022-02-26T08:50:27.836779Z",
     "shell.execute_reply": "2022-02-26T08:50:27.836380Z",
     "shell.execute_reply.started": "2022-02-26T08:50:27.833781Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words2 == words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ab62b9-42b2-412f-9cf4-0d8fcc041aef",
   "metadata": {},
   "source": [
    "This example is not very good in the actually mentioned context. It works as the amount of data we handle is small, but for a text that won't fit into RAM, this does not really help. A simple working example for this is slightly more complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e448df6f-cab0-4cab-a620-10115fb3660a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T08:50:28.217619Z",
     "iopub.status.busy": "2022-02-26T08:50:28.217388Z",
     "iopub.status.idle": "2022-02-26T08:50:28.222433Z",
     "shell.execute_reply": "2022-02-26T08:50:28.221949Z",
     "shell.execute_reply.started": "2022-02-26T08:50:28.217603Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'World',\n",
       " 'February',\n",
       " 'Eleven',\n",
       " 'Python',\n",
       " 'Data',\n",
       " 'Cloud',\n",
       " 'Wisdom',\n",
       " 'Fun']"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_size=4\n",
    "\n",
    "words2 = []\n",
    "\n",
    "with open(\"words.txt\", \"r\") as f:\n",
    "    word = \"\"\n",
    "    while chunk:=f.read(chunk_size):\n",
    "        for char in chunk:\n",
    "            if char == \"\\n\":\n",
    "                words2.append(word)\n",
    "                word = \"\"\n",
    "            else:\n",
    "                word += char\n",
    "    words2.append(word)\n",
    "    \n",
    "words2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "3414de8f-ec46-4ab9-a6e2-16f34cde9c20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T08:50:28.396691Z",
     "iopub.status.busy": "2022-02-26T08:50:28.396519Z",
     "iopub.status.idle": "2022-02-26T08:50:28.399691Z",
     "shell.execute_reply": "2022-02-26T08:50:28.399277Z",
     "shell.execute_reply.started": "2022-02-26T08:50:28.396674Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words2 == words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd144f22-f89c-48be-a70e-23e390369da9",
   "metadata": {},
   "source": [
    "Play with the `chunk_size` a little to convince yourself, that the algorithm is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c251fa-68d9-4647-9901-fba7154b1a08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23acfda-5533-4aa6-9a17-5f05e350361f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
